{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdZc8rVZSEvNswAgO9akq5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isnanmulia/colab-machinelearning/blob/main/ML_NLP_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tutorial uses codes from these sources, with several adjustments:\n",
        "- https://realpython.com/nltk-nlp-python/"
      ],
      "metadata": {
        "id": "90QSoOZ1JXB3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "xM-q3oMEL0N3"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence examples\n",
        "sentence_1 = 'Natural Language Processing allows your device to hear what you say, then understand the hidden meaning in your sentence, and finally act on that meaning.'\n",
        "sentence_2 = 'Classification sorts data into specific categories using a labeled dataset. Clustering is partitioning an unlabeled dataset into groups of similar objects.'\n",
        "sentence_3 = 'Erzurum is home to many different types of local cuisine, most famously, the Cag Kebab.'\n",
        "kalimat_1 = 'Kesatuan Integrated System adalah SIstem informasi Akademik bagi mahasiswa, dosen dan unit administrasi perkuliahan, baik dari sisi pembayaran, jadwal mata kuliah, dan pengumuman-pengumuman.'"
      ],
      "metadata": {
        "id": "HQawUFInMVo2"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "sent_tkn = sent_tokenize(sentence_2)\n",
        "word_tkn_1 = word_tokenize(sentence_1)\n",
        "word_tkn_2 = word_tokenize(sentence_2)\n",
        "word_tkn_3 = word_tokenize(sentence_3)\n",
        "kata_tkn_1 = word_tokenize(kalimat_1)\n",
        "\n",
        "print(sent_tkn)\n",
        "print('---')\n",
        "print(word_tkn_1)\n",
        "print('---')\n",
        "print(word_tkn_2)\n",
        "print('---')\n",
        "print(word_tkn_3)\n",
        "print('---')\n",
        "print(kata_tkn_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KReF3_XZt0k",
        "outputId": "e2ed05b7-8d11-4223-887f-41770487539e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Classification sorts data into specific categories using a labeled dataset.', 'Clustering is partitioning an unlabeled dataset into groups of similar objects.']\n",
            "---\n",
            "['Natural', 'Language', 'Processing', 'allows', 'your', 'device', 'to', 'hear', 'what', 'you', 'say', ',', 'then', 'understand', 'the', 'hidden', 'meaning', 'in', 'your', 'sentence', ',', 'and', 'finally', 'act', 'on', 'that', 'meaning', '.']\n",
            "---\n",
            "['Classification', 'sorts', 'data', 'into', 'specific', 'categories', 'using', 'a', 'labeled', 'dataset', '.', 'Clustering', 'is', 'partitioning', 'an', 'unlabeled', 'dataset', 'into', 'groups', 'of', 'similar', 'objects', '.']\n",
            "---\n",
            "['Erzurum', 'is', 'home', 'to', 'many', 'different', 'types', 'of', 'local', 'cuisine', ',', 'most', 'famously', ',', 'the', 'Cag', 'Kebab', '.']\n",
            "---\n",
            "['Kesatuan', 'Integrated', 'System', 'adalah', 'SIstem', 'informasi', 'Akademik', 'bagi', 'mahasiswa', ',', 'dosen', 'dan', 'unit', 'administrasi', 'perkuliahan', ',', 'baik', 'dari', 'sisi', 'pembayaran', ',', 'jadwal', 'mata', 'kuliah', ',', 'dan', 'pengumuman-pengumuman', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering stop words\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words_en = set(stopwords.words('english'))\n",
        "stop_words_id = set(stopwords.words('indonesian'))\n",
        "\n",
        "filtered_list_1 = [word for word in word_tkn_1 if not word in stop_words_en]\n",
        "filtered_list_2 = [word for word in word_tkn_2 if not word in stop_words_en]\n",
        "filtered_list_id_1 = [word for word in kata_tkn_1 if not word in stop_words_id]\n",
        "\n",
        "print(filtered_list_1)\n",
        "print('---')\n",
        "print(filtered_list_2)\n",
        "print('---')\n",
        "print(filtered_list_id_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp9_pbutcig-",
        "outputId": "d2c7a2e8-a403-42c5-c211-ffbe5c41f0f0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'allows', 'device', 'hear', 'say', ',', 'understand', 'hidden', 'meaning', 'sentence', ',', 'finally', 'act', 'meaning', '.']\n",
            "---\n",
            "['Classification', 'sorts', 'data', 'specific', 'categories', 'using', 'labeled', 'dataset', '.', 'Clustering', 'partitioning', 'unlabeled', 'dataset', 'groups', 'similar', 'objects', '.']\n",
            "---\n",
            "['Kesatuan', 'Integrated', 'System', 'SIstem', 'informasi', 'Akademik', 'mahasiswa', ',', 'dosen', 'unit', 'administrasi', 'perkuliahan', ',', 'sisi', 'pembayaran', ',', 'jadwal', 'mata', 'kuliah', ',', 'pengumuman-pengumuman', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming & Lemmatizing\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmed_words = [stemmer.stem(word) for word in word_tkn_2]\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in word_tkn_2]\n",
        "\n",
        "print(stemmed_words)\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIXjXi5AdtE7",
        "outputId": "dc98678e-a9bb-47a8-a526-13e3a5993657"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['classif', 'sort', 'data', 'into', 'specif', 'categori', 'use', 'a', 'label', 'dataset', '.', 'cluster', 'is', 'partit', 'an', 'unlabel', 'dataset', 'into', 'group', 'of', 'similar', 'object', '.']\n",
            "['Classification', 'sort', 'data', 'into', 'specific', 'category', 'using', 'a', 'labeled', 'dataset', '.', 'Clustering', 'is', 'partitioning', 'an', 'unlabeled', 'dataset', 'into', 'group', 'of', 'similar', 'object', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# POS tagging\n",
        "nltk.download('tagsets')\n",
        "pos_tagged_word_1 = nltk.pos_tag(word_tkn_1)\n",
        "pos_tagged_word_3 = nltk.pos_tag(word_tkn_3)\n",
        "print(pos_tagged_word_1)\n",
        "print(pos_tagged_word_3)\n",
        "# nltk.help.upenn_tagset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAtTQojEAwLW",
        "outputId": "08b0d781-4f70-4d9f-9b1a-c8e1b0f3f867"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('allows', 'VBZ'), ('your', 'PRP$'), ('device', 'NN'), ('to', 'TO'), ('hear', 'VB'), ('what', 'WP'), ('you', 'PRP'), ('say', 'VBP'), (',', ','), ('then', 'RB'), ('understand', 'VB'), ('the', 'DT'), ('hidden', 'JJ'), ('meaning', 'NN'), ('in', 'IN'), ('your', 'PRP$'), ('sentence', 'NN'), (',', ','), ('and', 'CC'), ('finally', 'RB'), ('act', 'VB'), ('on', 'IN'), ('that', 'DT'), ('meaning', 'NN'), ('.', '.')]\n",
            "[('Erzurum', 'NNP'), ('is', 'VBZ'), ('home', 'VBN'), ('to', 'TO'), ('many', 'JJ'), ('different', 'JJ'), ('types', 'NNS'), ('of', 'IN'), ('local', 'JJ'), ('cuisine', 'NN'), (',', ','), ('most', 'RBS'), ('famously', 'RB'), (',', ','), ('the', 'DT'), ('Cag', 'NNP'), ('Kebab', 'NNP'), ('.', '.')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Named-Entity Recognition\n",
        "from nltk.tree import Tree\n",
        "from nltk.draw.tree import TreeView\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "lotr_quote = \"It's a dangerous business, Frodo, going out your door.\"\n",
        "words_in_lotr_quote = word_tokenize(lotr_quote)\n",
        "lotr_pos_tags = nltk.pos_tag(words_in_lotr_quote)\n",
        "tree = nltk.ne_chunk(lotr_pos_tags, binary = True)\n",
        "print(lotr_pos_tags)\n",
        "print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx0o903ILwnc",
        "outputId": "4ff0baca-cda7-4cbe-f3f3-e3b31cf1bf1b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('It', 'PRP'), (\"'s\", 'VBZ'), ('a', 'DT'), ('dangerous', 'JJ'), ('business', 'NN'), (',', ','), ('Frodo', 'NNP'), (',', ','), ('going', 'VBG'), ('out', 'RP'), ('your', 'PRP$'), ('door', 'NN'), ('.', '.')]\n",
            "(S\n",
            "  It/PRP\n",
            "  's/VBZ\n",
            "  a/DT\n",
            "  dangerous/JJ\n",
            "  business/NN\n",
            "  ,/,\n",
            "  (NE Frodo/NNP)\n",
            "  ,/,\n",
            "  going/VBG\n",
            "  out/RP\n",
            "  your/PRP$\n",
            "  door/NN\n",
            "  ./.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Named-Entity Recognition (Advanced)\n",
        "def extract_ne(quote):\n",
        "  words = word_tokenize(quote, language='english')\n",
        "  tags = nltk.pos_tag(words)\n",
        "  tree = nltk.ne_chunk(tags, binary=True)\n",
        "  return set(\n",
        "      \" \".join(i[0] for i in t)\n",
        "      for t in tree\n",
        "      if hasattr(t, \"label\") and t.label() == \"NE\"\n",
        "      )\n",
        "\n",
        "text_NER = \"\"\"\n",
        " Men like Schiaparelli watched the red planet—it is odd, by-the-bye, that\n",
        " for countless centuries Mars has been the star of war—but failed to\n",
        " interpret the fluctuating appearances of the markings they mapped so well.\n",
        " All that time the Martians must have been getting ready.\n",
        "\n",
        " During the opposition of 1894 a great light was seen on the illuminated\n",
        " part of the disk, first at the Lick Observatory, then by Perrotin of Nice,\n",
        " and then by other observers. English readers heard of it first in the\n",
        " issue of Nature dated August 2.\"\"\"\n",
        "\n",
        "extract_ne(text_NER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCZ7sSDIJOD9",
        "outputId": "8bc54442-94a6-4b3d-c1ab-26f407bd988f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Lick Observatory', 'Mars', 'Nature', 'Perrotin', 'Schiaparelli'}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    }
  ]
}